{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murillor/miniconda3/envs/gcn/lib/python3.10/site-packages/torch_geometric/typing.py:31: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/murillor/miniconda3/envs/gcn/lib/python3.10/site-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/murillor/miniconda3/envs/gcn/lib/python3.10/site-packages/torch_geometric/typing.py:42: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/murillor/miniconda3/envs/gcn/lib/python3.10/site-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
      "/home/murillor/miniconda3/envs/gcn/lib/python3.10/site-packages/stdpopsim/catalog/HomSap/demographic_models.py:158: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  time=int(extended_GF.time.head(1) - 1), rate=0\n",
      "/home/murillor/miniconda3/envs/gcn/lib/python3.10/site-packages/stdpopsim/catalog/HomSap/demographic_models.py:161: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  time=int(extended_GF.time.tail(1) + 1), rate=0\n"
     ]
    }
   ],
   "source": [
    "import shutup\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tsgcn.simulation import MsprimeSimulation, run_sims\n",
    "from tsgcn.util import get_idle_gpu\n",
    "from tsgcn.data import TreeSequenceData, TreeSequencesDataset, windowed_div_from_ts, compute_ys\n",
    "from tsgcn.model import BiGCNModel, BiGCNEncoder\n",
    "\n",
    "import tskit\n",
    "\n",
    "shutup.please()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "# this device variable will get used later during training\n",
    "device = torch.device(f\"cuda:{get_idle_gpu()}\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONSTANTS\n",
    "seed = 11379\n",
    "num_reps = 1_000\n",
    "sp_name = \"HomSap\"\n",
    "chrom = None\n",
    "length = 1_000_000\n",
    "model_name =\"OutOfAfrica_3G09\"\n",
    "sample_size=10\n",
    "num_windows = 100\n",
    "model_num_windows = 20\n",
    "HomSap_chr13_OOA = MsprimeSimulation(seed, num_reps, sp_name, model_name, \"data/raw/\", chrom, length, sample_size, n_workers=512)\n",
    "model_breaks = np.linspace(0, HomSap_chr13_OOA.contig.length, model_num_windows+1)\n",
    "out_breaks = np.linspace(0, HomSap_chr13_OOA.contig.length, num_windows+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sims(HomSap_chr13_OOA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just exploring the output of convert_tseq\n",
    "from tsgcn.util import convert_tseq\n",
    "ts=tskit.load(HomSap_chr13_OOA.ts_paths[0])\n",
    "eix, ei, nf, sq = convert_tseq(ts)\n",
    "a=TreeSequenceData(edge_index=eix, edge_interval=ei, x = nf, sequence_length=sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing our dataset\n",
    "dataset = TreeSequencesDataset(\"data/\", HomSap_chr13_OOA.sims_path,seeds=HomSap_chr13_OOA.seed_array, y_name=\"windowed-diversity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_ys(dataset, windowed_div_from_ts, \"windowed-diversity\", num_windows=num_windows, n_workers=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_num_child(ts):\n",
    "    stats = np.zeros((ts.num_nodes, ), dtype=np.float32)\n",
    "    for tree in ts.trees():\n",
    "        for u in tree.nodes():\n",
    "            stats[u] += tree.num_children(u)\n",
    "    return torch.FloatTensor(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TreeSequenceData(x=[1419, 1], edge_index=[2, 7494], edge_interval=[2, 7494], sequence_length=1000000.0, y=[100])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = BiGCNEncoder(model_breaks, device, dataset[0].num_features, dataset[0].num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2346],\n",
       "        [0.2346],\n",
       "        [0.2346],\n",
       "        ...,\n",
       "        [0.2346],\n",
       "        [0.2346],\n",
       "        [0.2346]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_set, valid_set, test_set = random_split(dataset,[70*dataset.len()//100, 15*dataset.len()//100, 15*dataset.len()//100])\n",
    "\n",
    "trainloader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
    "validloader = DataLoader(valid_set, batch_size=1, shuffle=True)\n",
    "testloader = DataLoader(test_set, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(batch):\n",
    "    #return batch.x[:,0].unsqueeze(1)\n",
    "    return batch.y.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 0 | epoch avg. loss: 75709059.83178571 | validation avg. loss: 5023676.29666667\n",
      "Epochs: 1 | epoch avg. loss: 2783248.23660714 | validation avg. loss: 1532665.96791667\n",
      "Epochs: 2 | epoch avg. loss: 1028326.06111607 | validation avg. loss: 677268.54354167\n",
      "Epochs: 3 | epoch avg. loss: 484941.44696429 | validation avg. loss: 338603.79885417\n",
      "Epochs: 4 | epoch avg. loss: 246977.28233259 | validation avg. loss: 174548.76723958\n",
      "Epochs: 5 | epoch avg. loss: 126539.53973772 | validation avg. loss: 87999.74856771\n",
      "Epochs: 6 | epoch avg. loss: 62238.49425502 | validation avg. loss: 41644.50421875\n",
      "Epochs: 7 | epoch avg. loss: 28274.00491839 | validation avg. loss: 17848.81119792\n",
      "Epochs: 8 | epoch avg. loss: 11660.73476249 | validation avg. loss: 7032.29307780\n",
      "Epochs: 9 | epoch avg. loss: 4692.07811994 | validation avg. loss: 3035.63477987\n",
      "Epochs: 10 | epoch avg. loss: 2416.26430324 | validation avg. loss: 1958.30739543\n",
      "Epochs: 11 | epoch avg. loss: 1887.13746124 | validation avg. loss: 1752.54486491\n",
      "Epochs: 12 | epoch avg. loss: 1790.26831229 | validation avg. loss: 1699.81173177\n",
      "Epochs: 13 | epoch avg. loss: 1736.97330440 | validation avg. loss: 1644.44711548\n",
      "Epochs: 14 | epoch avg. loss: 1669.94560843 | validation avg. loss: 1570.39219889\n",
      "Epochs: 15 | epoch avg. loss: 1582.15794072 | validation avg. loss: 1473.48082194\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1793335)\n",
    "model = BiGCNModel(device, num_encoder_in_features=dataset.num_features, num_encoder_out_features=2,\n",
    "                    breaks=out_breaks, pooling=\"windowed_sum\", out_breaks=out_breaks)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=2e-4)\n",
    "num_epochs=100\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    num_batches = 0\n",
    "    for batch in trainloader:\n",
    "        num_batches+=1\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch)\n",
    "        #print(output.shape, batch.x[:,0].unsqueeze(1).shape)\n",
    "        loss = criterion(output,get_y(batch))\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_avg_loss = epoch_loss / num_batches\n",
    "    val_loss = 0\n",
    "    model.eval()\n",
    "    num_batches = 0\n",
    "    for batch in validloader:\n",
    "        num_batches+=1\n",
    "        batch.to(device)\n",
    "        output = model(batch)\n",
    "        loss = criterion(output,get_y(batch))\n",
    "        val_loss += loss.item()\n",
    "    val_avg_loss = val_loss/num_batches\n",
    "    \n",
    "    \n",
    "    print(f\"Epochs: {epoch} | epoch avg. loss: {train_avg_loss:.8f} | validation avg. loss: {val_avg_loss:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "real = []\n",
    "\n",
    "for batch in testloader:\n",
    "    \n",
    "    output = model(batch.to(device))\n",
    "    predictions.append(output.detach().cpu().numpy())\n",
    "    real.append(get_y(batch).detach().cpu().numpy())\n",
    "\n",
    "predictions = np.concatenate(predictions)\n",
    "real = np.concatenate(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.to(device)\n",
    "output = model(batch)\n",
    "criterion(output, get_y(batch))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing `Predicted~Observed` diversity within a single tree sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(get_y(batch).detach().cpu().numpy(), output.detach().cpu().numpy())\n",
    "plt.axline((0.7,0.7), slope=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now across all windows and tree sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate r^2 of real and predictions\n",
    "scipy.stats.pearsonr(real.flatten(), predictions.flatten())[0]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.scatter(real, predictions, alpha=0.3)\n",
    "plt.axline((0.7,0.7), slope=1)\n",
    "\n",
    "plt.ylabel('Predicted diversity')\n",
    "plt.xlabel('Observed diversity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
