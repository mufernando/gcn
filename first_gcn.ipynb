{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murillor/miniconda3/envs/gcn/lib/python3.10/site-packages/torch_geometric/typing.py:31: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/murillor/miniconda3/envs/gcn/lib/python3.10/site-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/murillor/miniconda3/envs/gcn/lib/python3.10/site-packages/torch_geometric/typing.py:42: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/murillor/miniconda3/envs/gcn/lib/python3.10/site-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
      "/home/murillor/miniconda3/envs/gcn/lib/python3.10/site-packages/stdpopsim/catalog/HomSap/demographic_models.py:158: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  time=int(extended_GF.time.head(1) - 1), rate=0\n",
      "/home/murillor/miniconda3/envs/gcn/lib/python3.10/site-packages/stdpopsim/catalog/HomSap/demographic_models.py:161: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  time=int(extended_GF.time.tail(1) + 1), rate=0\n"
     ]
    }
   ],
   "source": [
    "import shutup\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tsgcn.simulation import MsprimeSimulation\n",
    "from tsgcn.util import get_idle_gpu\n",
    "from tsgcn.data import TreeSequenceData, TreeSequencesDataset\n",
    "from tsgcn.model import BiGCNModel, BiGCNEncoder\n",
    "\n",
    "import tskit\n",
    "\n",
    "shutup.please()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# this device variable will get used later during training\n",
    "device = torch.device(f\"cuda:{get_idle_gpu()}\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONSTANTS\n",
    "seed = 11379\n",
    "num_reps = 200\n",
    "sp_name = \"HomSap\"\n",
    "chrom = \"chr13\"\n",
    "model_name =\"OutOfAfrica_3G09\"\n",
    "sample_size=10\n",
    "HomSap_chr13_OOA = MsprimeSimulation(seed, num_reps, sp_name, chrom, model_name, \"data/raw/\", sample_size, n_threads=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just exploring the output of convert_tseq\n",
    "from tsgcn.util import convert_tseq\n",
    "ts=tskit.load(HomSap_chr13_OOA.ts_paths[0])\n",
    "eix, ei, nf, sq = convert_tseq(ts)\n",
    "a=TreeSequenceData(edge_index=eix, edge_interval=ei, x = nf, sequence_length=sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing our dataset\n",
    "num_windows = 200\n",
    "dataset = TreeSequencesDataset(\"data/\", HomSap_chr13_OOA.sims_path,seeds=HomSap_chr13_OOA.seed_array)\n",
    "#dataset.process_y(num_windows=num_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TreeSequenceData(x=[141489, 1], edge_index=[2, 864663], edge_interval=[2, 864663], sequence_length=114364328.0, y=[200])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = BiGCNEncoder(1,4)\n",
    "a = t(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "train_set, valid_set, test_set = random_split(dataset,[120, 40, 40])\n",
    "\n",
    "trainloader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
    "validloader = DataLoader(valid_set, batch_size=1, shuffle=True)\n",
    "testloader = DataLoader(test_set, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(batch):\n",
    "    #return batch.x[:,0].unsqueeze(1)\n",
    "    return batch.y.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 0 | epoch avg. loss: 41899.58 | validation avg. loss: 247.35\n"
     ]
    }
   ],
   "source": [
    "breaks = np.linspace(0, HomSap_chr13_OOA.contig.length, num_windows+1)\n",
    "model = BiGCNModel(device, num_encoder_in_features=dataset.num_features, breaks=breaks, pooling=\"windowed_sum\")\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0005)\n",
    "num_epochs=50\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    num_batches = 0\n",
    "    for batch in trainloader:\n",
    "        num_batches+=1\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch)\n",
    "        #print(output.shape, batch.x[:,0].unsqueeze(1).shape)\n",
    "        loss = criterion(output,get_y(batch))\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_avg_loss = epoch_loss / num_batches\n",
    "    val_loss = 0\n",
    "    model.eval()\n",
    "    num_batches = 0\n",
    "    for batch in validloader:\n",
    "        num_batches+=1\n",
    "        batch.to(device)\n",
    "        output = model(batch)\n",
    "        loss = criterion(output,get_y(batch))\n",
    "        val_loss += loss.item()\n",
    "    val_avg_loss = val_loss/num_batches\n",
    "    \n",
    "    \n",
    "    print(f\"Epochs: {epoch} | epoch avg. loss: {train_avg_loss:.2f} | validation avg. loss: {val_avg_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "real = []\n",
    "\n",
    "for batch in testloader:\n",
    "    \n",
    "    output = model(batch.to(device))\n",
    "    predictions.append(output.detach().cpu().numpy())\n",
    "    real.append(get_y(batch).detach().cpu().numpy())\n",
    "\n",
    "predictions = np.concatenate(predictions)\n",
    "real = np.concatenate(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.to(device)\n",
    "output = model(batch)\n",
    "criterion(output, get_y(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(output.detach().cpu().numpy(), get_y(batch).detach().cpu().numpy())\n",
    "plt.axline((0.7,0.7), slope=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.scatter(real, predictions, alpha=0.1)\n",
    "plt.axline((0.7,0.7), slope=1)\n",
    "\n",
    "plt.ylabel('Predicted diversity')\n",
    "plt.xlabel('Observed diversity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.scatter(batch.x[:,0], output.detach().cpu().numpy())\n",
    "plt.ylabel('Predicted node time')\n",
    "plt.xlabel('Observed node time')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
