{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stdpopsim\n",
    "import numpy as np\n",
    "import os\n",
    "import tskit\n",
    "import multiprocessing.pool as mp\n",
    "import shutup\n",
    "shutup.please()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MsprimeSimulation():\n",
    "    def __init__(self, seed, num_reps, sp_name, chrom, model_name, sims_root_path, sample_size=10, n_threads=6):\n",
    "        # General configs\n",
    "        self.seed = seed\n",
    "        rng = np.random.default_rng(self.seed)\n",
    "        self.engine = stdpopsim.get_engine(\"msprime\")\n",
    "        self.n_threads = n_threads\n",
    "        # Simulation parameters\n",
    "        self.sp_name = sp_name\n",
    "        self.chrom = chrom\n",
    "        self.model_name = model_name\n",
    "        self.sample_size = sample_size\n",
    "        # Path parameters\n",
    "        self.sims_path = f\"{sims_root_path}{self.sp_name}/{self.chrom}/{self.model_name}/\"\n",
    "        os.makedirs(self.sims_path, exist_ok=True) # ensuring that sims_path exists\n",
    "        self.seed_array = rng.integers(1,2**31,num_reps)\n",
    "        self.ts_paths = [f\"{self.sims_path}/sim_{seed}.trees\" for seed in self.seed_array]\n",
    "        # Objects to be used in the simulation\n",
    "        self.species = stdpopsim.get_species(self.sp_name)\n",
    "        self.model = self.species.get_demographic_model(self.model_name)\n",
    "        self.contig = self.species.get_contig(self.chrom, mutation_rate=self.model.mutation_rate)\n",
    "        self.samples = {pop.name: self.sample_size for pop in self.model.populations}\n",
    "        self.run()\n",
    "    \n",
    "    def run_sim(self, seed):\n",
    "        tspath = f\"{self.sims_path}/sim_{seed}.trees\"\n",
    "        if not os.path.exists(tspath):\n",
    "            ts = self.engine.simulate(self.model, self.contig, self.samples, seed=seed)\n",
    "            ts.dump(tspath)\n",
    "        return tspath\n",
    "\n",
    "    def run(self):\n",
    "        with mp.ThreadPool(self.n_threads) as p:\n",
    "            results = list(p.imap(self.run_sim, self.seed_array))\n",
    "        assert results == self.ts_paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONSTANTS\n",
    "seed = 11379\n",
    "num_reps = 200\n",
    "sp_name = \"HomSap\"\n",
    "chrom = \"chr13\"\n",
    "model_name =\"OutOfAfrica_3G09\"\n",
    "sample_size=10\n",
    "HomSap_chr13_OOA = MsprimeSimulation(seed, num_reps, sp_name, chrom, model_name, \"data/raw/\", sample_size, n_threads=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts=tskit.load(HomSap_chr13_OOA.ts_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 161.0, 336.0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ts.breakpoints())[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = next(ts.trees())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = ts.tables.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_idx = np.row_stack((edges.parent, edges.child))\n",
    "edges_interval = np.row_stack((edges.left, edges.right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = 0\n",
    "right = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Dataset, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv, pool, SAGEConv, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeSequenceData(Data):\n",
    "    def __init__(self, x=None, edge_index=None, edge_attr=None, y=None, pos=None, edge_interval=None, sequence_length=None):\n",
    "        super().__init__(x, edge_index, edge_attr, y, pos)\n",
    "        self.edge_interval = edge_interval\n",
    "        self.sequence_length = sequence_length\n",
    "    def get_subgraph(self, left, right):\n",
    "        # selecting edges that overlap with the interval [left, right)\n",
    "        overlap = np.logical_and(self.edge_interval[0,:] < right, self.edge_interval[1,:] >= left)\n",
    "        return self.edge_index[:,overlap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tseq (ts):\n",
    "    edges = ts.tables.edges\n",
    "    edge_idx = torch.LongTensor(np.row_stack((edges.parent, edges.child)))\n",
    "    edge_interval = torch.FloatTensor(np.row_stack((edges.left, edges.right)))\n",
    "    node_features = []\n",
    "    assert np.all(np.diff(np.unique(edges_idx.flatten())) == 1) # there are no gaps in node ids\n",
    "    for node in ts.nodes():\n",
    "        node_features.append([node.time, node.is_sample()])\n",
    "    node_features = torch.FloatTensor(node_features)\n",
    "    return edge_idx, edge_interval, node_features, ts.sequence_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eix, ei, nf, sq = convert_tseq(ts)\n",
    "a=TreeSequenceData(edge_index=eix, edge_interval=ei, x = nf, sequence_length=sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1p/gjszg87s3glbwxkd5_x2j9x80000gn/T/ipykernel_26208/4112283796.py:9: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at /Users/runner/miniforge3/conda-bld/pytorch-recipe_1675740388473/work/aten/src/ATen/native/IndexingUtils.h:28.)\n",
      "  return self.edge_index[:,overlap]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([   331,    331,    413,    413,    447,    447,    618,    618,   1342,\n",
       "          1342,   2256,   2256,   3850,   3850,   5850,   5850,   7023,   7023,\n",
       "          9010,   9010,   9241,   9241,  10488,  10488,  10611,  10611,  11325,\n",
       "         11325,  11505,  11505,  11696,  11696,  12466,  12466,  12566,  12566,\n",
       "         13527,  13527,  14050,  14050,  15073,  15073,  15532,  15532,  15985,\n",
       "         15985,  17173,  17173,  18748,  18748,  20059,  20059,  21161,  21161,\n",
       "         21338,  21338,  21942,  21942,  24567,  24567,  24589,  24589,  25004,\n",
       "         25004,  25272,  25272,  25426,  25426,  29085,  29085,  29919,  29919,\n",
       "         29956,  29956,  31044,  31044,  33675,  33675,  36058,  36058,  40152,\n",
       "         40152,  40426,  40426,  42255,  42255,  45083,  45083,  47084,  47084,\n",
       "         47491,  47491,  51396,  51396,  52264,  52264,  52423,  52423,  53254,\n",
       "         53254,  60174,  60174,  62604,  62604,  68759,  68759,  76629,  76629,\n",
       "         86199,  86199,  89920,  89920,  90828,  90828, 107065, 107065, 121000,\n",
       "        121000, 133741, 133741, 134158, 134158, 134788, 134788,      4,     19,\n",
       "             8,     16,     31,     32,     28,     33,     30,     36,     46,\n",
       "            53,     42,     52,     35,     43,     41,     51,     27,     38,\n",
       "            45,   7023,     20,     34,    413,   3850,     21,     22,     47,\n",
       "            54,     50,     59,    618,  10488,  10611,  11696,     56,     58,\n",
       "            48,   9010,     24,   1342,     44,   2256,     49,     57,     26,\n",
       "         15073,     40,  15532,      1,      5,   9241,  11325,     23,  11505,\n",
       "            18,  12466,     37,  21338,      3,     11,     29,  17173,   5850,\n",
       "         15985,    447,  18748,  13527,  21161,  14050,  25004,      2,      6,\n",
       "         25272,  29085,     12,  24589,     15,    331,      0,  24567,  12566,\n",
       "         25426,     25,  40152,  29919,  33675,  21942,  45083,     17,     55,\n",
       "            39,  36058,  29956,  47084,     13,  51396,     10,  40426,      9,\n",
       "            14,      7,  42255,  20059,  62604,  47491,  53254,  60174,  68759,\n",
       "         31044,  86199,  52264,  52423,  89920,  90828,  76629, 107065,  76629,\n",
       "        107065,  76629, 107065,  76629, 107065])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.get_subgraph(100,500).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeSequencesDataset(Dataset):\n",
    "    def __init__(self, root, raw_root, transform=None, pre_transform=None, pre_filter=None, seeds=None, y_func=None, y_name=None):\n",
    "        self.seeds = seeds\n",
    "        self.raw_root = raw_root\n",
    "        if y_func is None:\n",
    "            assert y_name is None\n",
    "            def _windowed_div_from_ts(ts, num_windows=1):\n",
    "                windows = np.linspace(0, ts.sequence_length, num_windows+1)\n",
    "                div = ts.diversity(windows=windows, mode=\"branch\")\n",
    "                return torch.FloatTensor(div)\n",
    "            self.y_func = _windowed_div_from_ts\n",
    "            self.y_name = \"win-div\"\n",
    "        else:\n",
    "            assert y_name is not None\n",
    "            self.y_func = y_func\n",
    "            self.y_name = y_name\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [f'{self.raw_root}sim_{s}.trees' for s in self.seeds]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [f'tseq_{i}.pt' for i in range(len(self.seeds))]\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        for raw_file_name, i in zip(self.raw_file_names, range(len(self.seeds))):\n",
    "            ts = tskit.load(raw_file_name)\n",
    "            edge_idx, edge_int, node_features, seq_len = convert_tseq(ts)\n",
    "            data = TreeSequenceData(x=node_features, edge_index = edge_idx, edge_interval=edge_int, sequence_length=seq_len)\n",
    "            torch.save(data, os.path.join(self.processed_dir, f'tseq_{i}.pt'))\n",
    "        self.process_y()\n",
    "    \n",
    "    def process_y(self, y_func=None, y_name = None, **kwargs):\n",
    "        if y_func is None:\n",
    "            assert y_name is None\n",
    "            y_func = self.y_func\n",
    "            y_name = self.y_name\n",
    "        else:\n",
    "            self.y_func = y_func\n",
    "            self.y_name = y_name\n",
    "        for raw_file_name, i in zip(self.raw_file_names, range(len(self.seeds))):\n",
    "            ts = tskit.load(raw_file_name)\n",
    "            y = y_func(ts, **kwargs)\n",
    "            torch.save(y, os.path.join(self.processed_dir, f'y_{y_name}_{i}.pt'))\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        data = torch.load(os.path.join(self.processed_dir, f'tseq_{idx}.pt'))\n",
    "        y = torch.load( os.path.join(self.processed_dir, f'y_{self.y_name}_{idx}.pt'))\n",
    "        data.y = y\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TreeSequencesDataset(\"data/\", HomSap_chr13_OOA.sims_path,seeds=HomSap_chr13_OOA.seed_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGCNEncoder(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A bidirectional GCN that takes a TreeSequenceData object as input and returns a vector of node embeddings.\n",
    "    Node embeddings are updated by a GCN layer applied to edges that overlap with a window at a time, going both forwards and backwards.\n",
    "    Forward and backward embeddings are summed to get the final embedding.\n",
    "    TODO: \n",
    "        - add a way to specify sequence breaks\n",
    "        - remove manual seed\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features=4):\n",
    "        super(BiGCNEncoder, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        torch.manual_seed(12345)\n",
    "        # Layers to do the Graph convolutions (return vector of node embeddings with num_hidden features)\n",
    "        self.conv_f = SAGEConv(self.in_features, self.out_features)\n",
    "        self.conv_b = SAGEConv(self.in_features, self.out_features)\n",
    "\n",
    "    def forward(self, data):\n",
    "        breaks = [0, data.sequence_length]\n",
    "        x_f = data.x.clone()\n",
    "        x_b = data.x.clone()\n",
    "        #print(x_f.shape, x_b.shape)\n",
    "        for i in range(len(breaks)-1):\n",
    "            left = breaks[i]\n",
    "            right = breaks[i+1]\n",
    "            #print(left,right)\n",
    "            subgraph_edge = data.get_subgraph(left, right)\n",
    "            x_f = self.conv_f(x_f, subgraph_edge)\n",
    "        for i in range(len(breaks)-1, 0, -1):\n",
    "            left = breaks[i-1]\n",
    "            right = breaks[i]\n",
    "            #print(left, right)\n",
    "            subgraph_edge = data.get_subgraph(left, right)\n",
    "            x_b = self.conv_b(x_b, subgraph_edge)\n",
    "        x = torch.concat((x_f,x_b), 1)\n",
    "        #print(x_f.shape, x_b.shape)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1p/gjszg87s3glbwxkd5_x2j9x80000gn/T/ipykernel_26208/4112283796.py:9: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at /Users/runner/miniforge3/conda-bld/pytorch-recipe_1675740388473/work/aten/src/ATen/native/IndexingUtils.h:28.)\n",
      "  return self.edge_index[:,overlap]\n"
     ]
    }
   ],
   "source": [
    "t = BiGCNEncoder(2,4)\n",
    "a = t(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([141728, 8])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -809.2023, -3858.8579, -3357.0652, -2380.9363,  3554.5234,  3758.5535,\n",
       "        -1398.4863, -1740.2633], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_sum_pooling(x, data, breaks=None):\n",
    "    \"\"\"\n",
    "    Pooling function that pools the embeddings of nodes in a window by summing them.\n",
    "    Returns a tensor of shape (num_windows, num_encoder_out_features)\n",
    "    \"\"\"\n",
    "    if breaks is None:\n",
    "        breaks = [0, data.sequence_length]\n",
    "    x_pooled = torch.zeros(len(breaks)-1, x.shape[1], requires_grad=True)\n",
    "    for i in range(len(breaks)-1):\n",
    "        left = breaks[i]\n",
    "        right = breaks[i+1]\n",
    "        nodes_in_window = data.get_subgraph(left, right).flatten()\n",
    "        pooled = torch.sum(x[nodes_in_window], dim=0)\n",
    "        x[i,0] = pooled[0]\n",
    "        x[i,1] = pooled[1]\n",
    "        #print(x_pooled,flush=True)\n",
    "    return x_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGCNModel(torch.nn.Module):\n",
    "    def __init__(self, num_encoder_in_features=None, num_encoder_out_features=2, mlp_channels=None, pooling=\"windowed_sum\", breaks=None):\n",
    "        super(BiGCNModel, self).__init__()\n",
    "        self.breaks = breaks\n",
    "        self.encoder = BiGCNEncoder(num_encoder_in_features, num_encoder_out_features)\n",
    "        #self.mlp = models.MLP(mlp_channels)\n",
    "        self.lin1 = Linear(num_encoder_out_features,16)\n",
    "        self.lin2 = Linear(16,1)\n",
    "        #if pooling == \"windowed_sum\":\n",
    "        self.pooling = windowed_sum_pooling\n",
    "\n",
    "    def forward(self, data):\n",
    "        # node embeddings num_nodes x num_encoder_out_features\n",
    "        x = self.encoder(data)\n",
    "        #print(\"Printing X\")\n",
    "        #print(x)\n",
    "        #exit\n",
    "        # pooled embeddings num_windows x num_encoder_out_features\n",
    "        h = self.pooling(x, data)\n",
    "        #print(h)\n",
    "        #nodes_in_window = data.get_subgraph(0, data.sequence_length).flatten()\n",
    "        #h = torch.sum(x[nodes_in_window], dim=0)\n",
    "        # final output num_windows x 1\n",
    "        #print(h.shape)\n",
    "        h = F.relu(self.lin1(h))\n",
    "        out = F.relu(self.lin2(h))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "train_set, valid_set, test_set = random_split(dataset,[120, 40, 40])\n",
    "\n",
    "trainloader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
    "validloader = DataLoader(valid_set, batch_size=1, shuffle=True)\n",
    "testloader = DataLoader(test_set, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiGCNModel(num_encoder_in_features=dataset.num_features)\n",
    "\n",
    "model(next(iter(trainloader))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0].x[:,0].unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(output, batch.x[:,0].unsqueeze(1)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiGCNModel(num_encoder_in_features=dataset.num_features)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.1)\n",
    "num_epochs=10\n",
    "device = torch.device(\"cpu\")\n",
    "criterion = torch.nn.L1Loss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    num_batches = 0\n",
    "    for batch in trainloader:\n",
    "        num_batches+=1\n",
    "        batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch)\n",
    "        #print(output.shape, batch.x[:,0].unsqueeze(1).shape)\n",
    "        loss = criterion(output,batch.y.unsqueeze(1).type(torch.FloatTensor))\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_avg_loss = epoch_loss / num_batches\n",
    "    val_loss = 0\n",
    "    model.eval()\n",
    "    num_batches = 0\n",
    "    for batch in validloader:\n",
    "        num_batches+=1\n",
    "        batch.to(device)\n",
    "        output = model(batch)\n",
    "        loss = criterion(output,batch.y.unsqueeze(1).type(torch.FloatTensor))\n",
    "        val_loss += loss.item()\n",
    "    val_avg_loss = val_loss/num_batches\n",
    "    \n",
    "    \n",
    "    print(f\"Epochs: {epoch} | epoch avg. loss: {train_avg_loss:.2f} | validation avg. loss: {val_avg_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "real = []\n",
    "\n",
    "for batch in testloader:\n",
    "    \n",
    "    output = model(batch.to(device))\n",
    "    predictions.append(output.detach().cpu().numpy())\n",
    "    real.append(batch.y.detach().cpu().numpy())\n",
    "\n",
    "predictions = np.concatenate(predictions)\n",
    "real = np.concatenate(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.scatter(real,predictions)\n",
    "plt.ylabel('Predicted diversity')\n",
    "plt.xlabel('Observed diversity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
